# Mini Question Answering System using DistilBERT

This project is a simple interactive **Question Answering System** built using the **DistilBERT** model and **Gradio** interface. The system takes a paragraph as context and answers any question related to it.  
It demonstrates how Natural Language Processing (NLP) models can be used to understand and extract information from text using a user-friendly web interface.

---

## Project Overview

This project uses **DistilBERT**, a lightweight and faster version of the BERT model developed by Hugging Face. It is trained on large-scale language understanding tasks and fine-tuned for **Question Answering (QA)**.  
The **Gradio** library is used to create an interactive interface where users can input a question and get an instant answer based on the given context.

The project is implemented in **Google Colab** and saved as a `.ipynb` notebook.

---

## Key Features

- Uses **DistilBERT** model for high-quality question answering  
- **Interactive Gradio Interface** for easy testing and visualization  
- Takes user input for questions and provides accurate answers from a given paragraph  
- Simple and clean UI with text input and output boxes  
- Can be extended with custom datasets or longer contexts  

---

## Technologies Used

| Tool / Library | Purpose |
|-----------------|----------|
| **Python** | Core programming language |
| **Transformers (Hugging Face)** | Pretrained NLP model (DistilBERT) |
| **Gradio** | Web interface for user interaction |
| **Google Colab** | Cloud-based development environment |

---

## Project Structure

**Screenshots:**

![Interface Screenshot 1](Screenshots/ss%201.png)
![Interface Screenshot 2](Screenshots/ss%202.png)

